import os
from crewai.tools import tool
from crewai_tools import PDFSearchTool
import google.generativeai as genai
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
import json

token = "AIzaSyDpcS2ySvzyHoGdK1zfJ3rYynWIBTrNAtY"

genai.configure(api_key=token)
model = genai.GenerativeModel("gemini-1.5-flash")


# Load an Arabic-compatible embedding model
model_name = "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
model_kwargs = {"device": "cuda"}  # Use CUDA if available

embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)

def encode_pdfs(paths, chunk_size=2000, chunk_overlap=200):
    """
    Load and encode multiple PDF files into a single FAISS vector store.
    
    :param paths: List of PDF file paths.
    :param chunk_size: Size of text chunks.
    :param chunk_overlap: Overlapping size between chunks.
    :return: FAISS vector store containing indexed document embeddings.
    """
    all_texts = []
    
    for path in paths:
        # Load the PDF
        loader = PyPDFLoader(path)
        documents = loader.load()
        
        # Split the text into chunks
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len
        )
        chunks = text_splitter.split_documents(documents)
        
        # Extract text content
        texts = [chunk.page_content.encode("utf-8", "ignore").decode() for chunk in chunks]
        all_texts.extend(texts)  # Collect all texts from different books

    # Create a single FAISS vector store from all documents
    vectorstore = FAISS.from_texts(all_texts, embeddings)
    
    return vectorstore

# Paths of the three books
pdf_paths = [r'books\\Book1.pdf', r'books\\Book2.pdf']

# Encode all books into a single vector store
chunks_vector_store = encode_pdfs(pdf_paths, chunk_size=2000, chunk_overlap=200)

# Create a retriever from the combined vector store
chunks_query_retriever = chunks_vector_store.as_retriever(search_kwargs={"k": 5})

def prompt_template(
    context: str, age: int = 20, weight: float = 60.0, height: float = 175.0
) -> str:
    prompt = f""" 
    ุฃูุช ูุณุงุนุฏ ุบุฐุงุฆู ุฐููุ ูููุชู ุชูุฏูู ูุธุงู ุบุฐุงุฆู ุตุญู ููุถุญ ููู ุงูุณุนุฑุงุช ุงูุญุฑุงุฑูุฉ ุงูููุงุณุจุฉ ูููุณุชุฎุฏู ุจูุงุกู ุนูู ุงูุจูุงูุงุช ุงูุดุฎุตูุฉ ุงูุชุงููุฉ:
    
    ๐ง ุงูุนูุฑ: {age} ุณูุฉ  
    โ๏ธ ุงููุฒู: {weight} ูุฌู  
    ๐ ุงูุทูู: {height} ุณู  
    
    ูุฏ ูููู ูุฏู ุงููุณุชุฎุฏู ุชุงุฑูุฎ ูุฑุถูุ ูู ุงูุจุฏุงูุฉ ุงุทูุจ ููู ูุฐู ุงููุนูููุงุช ุญุชู ุชูุฏู ูุชุงุฆุฌ ูุนุงูุฉ.  
    ุฅุฐุง ุฑูุถ ุฅุนุทุงุก ุงููุนูููุงุช ุงูุดุฎุตูุฉุ ููููู ุชูุฏูู ูุตุงุฆุญ ุนุงูุฉ ููุชุบุฐูุฉ ุงูุตุญูุฉ.  
    ูุฅุฐุง ุฃุนุทุงู ุงููุนูููุงุช ุงูุดุฎุตูุฉุ ููููู ุชูุฏูู ูุตุงุฆุญ ุชุบุฐูุฉ ูุฎุตุตุฉ ูู.  
        
    ๐น ุถุน ูู ุงุนุชุจุงุฑู ุชูุงุฒู ุงูุนูุงุตุฑ ุงูุบุฐุงุฆูุฉุ ููุฏู ุงูุชุฑุงุญูุง ูุญุชูู ุนูู ุงูุจุฑูุชููุ ุงููุฑุจูููุฏุฑุงุชุ ูุงูุฏููู ุงูุตุญูุฉ.  
    ๐น ุฅุฐุง ูุงูุช ุงููุฌุจุฉ ุบูุฑ ููุงุณุจุฉ ูุตุญุฉ ุงููุณุชุฎุฏูุ ุงูุชุฑุญ ุจุฏููุงู ุตุญููุง ูุดุงุจููุง.  
    ๐น ุงุฌุนู ุงูุฅุฌุงุจุฉ ูุงุถุญุฉ ูููุฌุฒุฉ ูู **ุฎูุณ ุฌูู** ููุท.  

    ๐ ูุนูููุงุช ูุฑุฌุนูุฉ:  
    {context}

    ๐ฝ๏ธ ุงูุชุฑุงุญ ูุฌุจุฉ ุตุญูุฉ:
    """
    return prompt

@tool
def run_rag(
    age: int = 20, weight: float = 60.0, height: float = 175.0, prompt: str = "ููู ูููููู ุญุณุงุจ ุงูุณุนุฑุงุช ุงูุญุฑุงุฑูุฉ ุงููุทููุจุฉ ูููููุงุ"
) -> str:
    """๐ ูุณุชุฑุฌุน ุงููุนูููุงุช ุงูุบุฐุงุฆูุฉ ุจูุงุกู ุนูู ุจูุงูุงุช ุงููุณุชุฎุฏู ุงูุดุฎุตูุฉ ูุซู ุงูุนูุฑุ ุงููุฒูุ ุงูุทููุ ููุณุชูู ุงููุดุงุท.

    โ ูุนุชูุฏ ุนูู `FAISS` ูุงุณุชุฑุฌุงุน ุงููุนูููุงุช ุงูุบุฐุงุฆูุฉ ุฐุงุช ุงูุตูุฉ ูู ุงููุณุชูุฏุงุชุ  
    ุซู ูููู ุจุชูุฑูุฑ ุงูุจูุงูุงุช ุฅูู `Meta-Llama-3.3-70B-Instruct` ูุฅูุดุงุก ุฅุฌุงุจุฉ ูุฎุตุตุฉ ุชุญุชูู ุนูู ุชูุฏูุฑ ููุณุนุฑุงุช ุงูุญุฑุงุฑูุฉ ุงููุทููุจุฉุ  
    ุจุงูุฅุถุงูุฉ ุฅูู ุชูุตูุงุช ุบุฐุงุฆูุฉ ููุงุณุจุฉ.

    ๐น **ุงููุนุทูุงุช**:
    - `age` (int, default=30): ุนูุฑ ุงููุณุชุฎุฏู ุจุงูุณููุงุช.
    - `weight` (float, default=70.0): ูุฒู ุงููุณุชุฎุฏู ุจุงูููููุบุฑุงู.
    - `height` (float, default=175.0): ุทูู ุงููุณุชุฎุฏู ุจุงูุณูุชููุชุฑ.
    - `prompt` (str, default="ููู ูููููู ุญุณุงุจ ุงูุณุนุฑุงุช ุงูุญุฑุงุฑูุฉ ุงููุทููุจุฉ ูููููุงุ"): ุงุณุชูุณุงุฑ ุงููุณุชุฎุฏู ุงูุฅุถุงูู ุฃู ุฃู ุดุฑูุท ุบุฐุงุฆูุฉ ุฎุงุตุฉ.

    ๐น **ุงููุฎุฑุฌุงุช**:
    - (str): ุฅุฌุงุจุฉ ุชุญุชูู ุนูู ุฅุฌูุงูู ุงูุณุนุฑุงุช ุงูุญุฑุงุฑูุฉ ุงููุทููุจุฉ ูููููุงุ ูุชูุตูุงุช ุบุฐุงุฆูุฉ ูุจููุฉ ุนูู ุงูุจูุงูุงุช ุงููุฏุฎูุฉ.
    """
    results = chunks_query_retriever.get_relevant_documents(prompt)
    response = model.generate_content(prompt_template(results, age, weight, height))
    return response.text



@tool 
def load_json_file(file_path="data.json"):
    """
    ูููู ุจุชุญููู ุจูุงูุงุช ูู ููู JSON ูุฅุฑุฌุงุนูุง ูุณูุณูุฉ ูุตูุฉ ููุณูุฉ.
    
    :param file_path: ูุณุงุฑ ููู JSON.
    :return: ูุญุชูู JSON ูุณูุณูุฉ ูุตูุฉ.
    """
    try:
        with open(file_path, "r", encoding="utf-8") as file:
            json_data = json.load(file)  # โ ูุฑุงุกุฉ JSON
            return json.dumps(json_data, indent=4, ensure_ascii=False)  # โ ุชุญููู JSON ุฅูู ูุต ููุณู
    except FileNotFoundError:
        return "โ๏ธ ุงูููู ุบูุฑ ููุฌูุฏ."
    except json.JSONDecodeError:
        return "โ๏ธ ุฎุทุฃ ูู ุชุญููู ุจูุงูุงุช JSON."


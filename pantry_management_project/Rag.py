from crewai.tools import tool
from crewai_tools import PDFSearchTool
import google.generativeai as genai
import os
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings

path=r'books\\Book1.pdf'

token = "AIzaSyDpcS2ySvzyHoGdK1zfJ3rYynWIBTrNAtY"

genai.configure(api_key=token)
model = genai.GenerativeModel("gemini-1.5-flash")


# Load an Arabic-compatible embedding model
model_name = "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
model_kwargs = {"device": "cuda"}  # Use CUDA if available

embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)

def encode_pdf(path, chunk_size=2000, chunk_overlap=200):
    # Load PDF documents
    loader = PyPDFLoader(path)
    documents = loader.load()

    # Split documents into chunks
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len
    )
    chunks = text_splitter.split_documents(documents)

    texts = [chunk.page_content.encode("utf-8", "ignore").decode() for chunk in chunks]

    # Create vector store using FAISS
    vectorstore = FAISS.from_texts(texts, embeddings)

    return vectorstore

chunks_vector_store = encode_pdf(path, chunk_size=2000, chunk_overlap=200)
chunks_query_retriever = chunks_vector_store.as_retriever(search_kwargs={"k": 5})


def prompt_template(context,age=22, weight=65, meal="ุงูุนุดุงุก"):
    prompt = f"""
    ุฃูุช ูุณุงุนุฏ ุบุฐุงุฆู ุฐููุ ูููุชู ุชูุฏูู ูุธุงู ุบุฐุงุฆู ุตุญู ุจูุงุกู ุนูู ุนูุฑ ุงููุณุชุฎุฏูุ ูุฒููุ ูุงููุฌุจุฉ ุงูุชู ูุฑูุฏูุง.
    ุงุณุชุฎุฏู ุงููุนูููุงุช ุงูุชุงููุฉ ููุฑุฌุน ูุฅูุดุงุก ุงูุชุฑุงุญ ุตุญู ูููุฌุจุฉ ุงููุฎุชุงุฑุฉ.

    โ ุงูุนูุฑ: {age} ุณูุฉ
    โ ุงููุฒู: {weight} ูุฌู
    โ ุงููุฌุจุฉ ุงููุทููุจุฉ: {meal}

    ๐น ุถุน ูู ุงุนุชุจุงุฑู ุชูุงุฒู ุงูุนูุงุตุฑ ุงูุบุฐุงุฆูุฉุ ููุฏู ุงูุชุฑุงุญูุง ูุญุชูู ุนูู ุงูุจุฑูุชููุ ุงููุฑุจูููุฏุฑุงุชุ ูุงูุฏููู ุงูุตุญูุฉ.
    ๐น ุฅุฐุง ูุงูุช ุงููุฌุจุฉ ุบูุฑ ููุงุณุจุฉ ูุตุญุฉ ุงููุณุชุฎุฏูุ ุงูุชุฑุญ ุจุฏููุงู ุตุญููุง ูุดุงุจููุง.
    ๐น ุงุฌุนู ุงูุฅุฌุงุจุฉ ูุงุถุญุฉ ูููุฌุฒุฉ ูู **ุซูุงุซ ุฌูู** ููุท.

    ๐ ูุนูููุงุช ูุฑุฌุนูุฉ:
    {context}

    ๐ฝ๏ธ ุงูุชุฑุงุญ ูุฌุจุฉ ุตุญูุฉ:
    """
    return prompt

@tool
def run_rag(prompet: str)->str:
  """๐ ูุณุชุฑุฌุน ุงููุนูููุงุช ูู PDF ููุณุชุฎุฏู Gemini 1.5 ููุฅุฌุงุจุฉ ุนูู ุงุณุชูุณุงุฑุงุช ุงููุณุชุฎุฏู.

    โ ูุชู ุงูุจุญุซ ูู ุงููุณุชูุฏุงุช ุจุงุณุชุฎุฏุงู `FAISS` ูุงุณุชุฑุฌุงุน ุงููุนูููุงุช ุงูุบุฐุงุฆูุฉ ุงููุฑุชุจุทุฉ ุจุงูุณุคุงูุ
    ุซู ูุชู ุชูุฑูุฑ ุงูุจูุงูุงุช ุฅูู `Gemini 1.5` ูุฅูุดุงุก ุฅุฌุงุจุฉ ูุฎุตุตุฉ.

    ๐น **ุงููุนุทูุงุช**:
    - `query` (str): ุงุณุชูุณุงุฑ ุงููุณุชุฎุฏู.

    ๐น **ุงููุฎุฑุฌุงุช**:
    - (str): ุฅุฌุงุจุฉ ุชุญุชูู ุนูู ุชูุตูุฉ ุบุฐุงุฆูุฉ ูุจููุฉ ุนูู ุงููุนูููุงุช ุงููุณุชุฑุฌุนุฉ ูู ุงููุณุชูุฏุงุช.
    """
  results = chunks_query_retriever.get_relevant_documents(prompet)
  nutrition_info = results
  response = model.generate_content(prompt_template(nutrition_info))
  return response.text




